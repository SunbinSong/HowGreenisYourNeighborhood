{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc17fa21-3977-47cd-8475-c354ae8bdf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Greater_London', 2016, 965), ('Greater_London', 2020, 1890), ('Greater_London', 2018, 965), ('Greater_London', 2023, 482), ('Greater_London', 2022, 965), ('Greater_London', 2017, 1890), ('Greater_London', 2020, 965), ('Greater_London', 2015, 1890), ('Greater_London', 2016, 2816), ('Greater_London', 2018, 2816), ('Greater_London', 2018, 482), ('Greater_London', 2016, 482), ('Greater_London', 2017, 965), ('Greater_London', 2019, 1890), ('Greater_London', 2021, 1890), ('Greater_London', 2022, 482), ('Greater_London', 2015, 965), ('Greater_London', 2020, 2816), ('Greater_London', 2019, 965), ('Greater_London', 2020, 482), ('Greater_London', 2021, 965), ('Greater_London', 2023, 1890), ('Greater_London', 2017, 2816), ('Greater_London', 2017, 482), ('Greater_London', 2015, 2816), ('Greater_London', 2016, 1890), ('Greater_London', 2023, 965), ('Greater_London', 2015, 482), ('Greater_London', 2018, 1890), ('Greater_London', 2019, 482), ('Greater_London', 2019, 2816), ('Greater_London', 2021, 2816), ('Greater_London', 2021, 482), ('Greater_London', 2022, 1890), ('Greater_Manchester', 2021, 2816), ('Greater_Manchester', 2020, 965), ('Greater_Manchester', 2018, 965), ('Greater_Manchester', 2022, 1890), ('Greater_Manchester', 2016, 2816), ('Greater_Manchester', 2015, 1890), ('Greater_Manchester', 2016, 482), ('Greater_Manchester', 2019, 1890), ('Greater_Manchester', 2022, 965), ('Greater_Manchester', 2015, 965), ('Greater_Manchester', 2017, 1890), ('Greater_Manchester', 2018, 482), ('Greater_Manchester', 2018, 2816), ('Greater_Manchester', 2020, 2816), ('Greater_Manchester', 2020, 482), ('Greater_Manchester', 2019, 965), ('Greater_Manchester', 2021, 1890), ('Greater_Manchester', 2023, 1890), ('Greater_Manchester', 2017, 965), ('Greater_Manchester', 2022, 482), ('Greater_Manchester', 2022, 2816), ('Greater_Manchester', 2021, 965), ('Greater_Manchester', 2023, 965), ('Greater_Manchester', 2015, 2816), ('Greater_Manchester', 2015, 482), ('Greater_Manchester', 2016, 1890), ('Greater_Manchester', 2019, 2816), ('Greater_Manchester', 2019, 482), ('Greater_Manchester', 2017, 2816), ('Greater_Manchester', 2017, 482), ('Greater_Manchester', 2016, 965), ('Greater_Manchester', 2018, 1890), ('Greater_Manchester', 2020, 1890), ('Greater_Manchester', 2021, 482), ('Greater_Manchester', 2023, 2816), ('Greater_Manchester', 2023, 482), ('West_Midlands', 2019, 2816), ('West_Midlands', 2019, 482), ('West_Midlands', 2020, 1890), ('West_Midlands', 2016, 965), ('West_Midlands', 2018, 1890), ('West_Midlands', 2021, 2816), ('West_Midlands', 2021, 482), ('West_Midlands', 2020, 965), ('West_Midlands', 2023, 2816), ('West_Midlands', 2023, 482), ('West_Midlands', 2022, 1890), ('West_Midlands', 2015, 1890), ('West_Midlands', 2018, 965), ('West_Midlands', 2022, 965), ('West_Midlands', 2016, 2816), ('West_Midlands', 2016, 482), ('West_Midlands', 2015, 965), ('West_Midlands', 2017, 1890), ('West_Midlands', 2017, 2816), ('West_Midlands', 2019, 1890), ('West_Midlands', 2020, 482), ('West_Midlands', 2020, 2816), ('West_Midlands', 2018, 2816), ('West_Midlands', 2017, 965), ('West_Midlands', 2018, 482), ('West_Midlands', 2019, 965), ('West_Midlands', 2022, 2816), ('West_Midlands', 2022, 482), ('West_Midlands', 2021, 1890), ('West_Midlands', 2023, 1890), ('West_Midlands', 2015, 2816), ('West_Midlands', 2015, 482), ('West_Midlands', 2021, 965), ('West_Midlands', 2023, 965), ('West_Midlands', 2016, 1890), ('West_Midlands', 2017, 482)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 10:20:14,883 - INFO - Memory usage: 1008.90625 MB\n",
      "2024-08-01 10:20:14,883 - INFO - Memory usage: 1008.8828125 MB\n",
      "2024-08-01 10:20:14,885 - INFO - Processing Greater_London, 2023, 2816\n",
      "2024-08-01 10:20:14,885 - INFO - Processing Greater_London, 2022, 2816\n",
      "2024-08-02 04:25:43,324 - INFO - DONE Greater_London, 2022, 2816\n",
      "2024-08-02 06:26:59,244 - INFO - DONE Greater_London, 2023, 2816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "from filelock import FileLock\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import logging\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "# Suppress specific FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Global constants\n",
    "buffer_radii = [2816, 1890, 965, 482]  # in meters\n",
    "postcode_data_path = \"ukpostcodes.csv\"\n",
    "chunk_size = 700  # Define a chunk size for processing\n",
    "\n",
    "# Prepare and convert postcode data\n",
    "postcode_data = pd.read_csv(postcode_data_path)\n",
    "postcode_data = gpd.GeoDataFrame(\n",
    "    postcode_data,\n",
    "    geometry=gpd.points_from_xy(postcode_data.longitude, postcode_data.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(epsg=27700)\n",
    "\n",
    "def log_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    logging.info(f\"Memory usage: {process.memory_info().rss / (1024 ** 2)} MB\")\n",
    "\n",
    "\n",
    "def process_task(city, year, radius, city_boundaries_path):\n",
    "    try:\n",
    "        log_memory_usage()\n",
    "        logging.info(f\"Processing {city}, {year}, {radius}\")\n",
    "        output_file = f\"multiprocessing_shp{outputfile[city]}.csv\"\n",
    "        lock_file = f\"multiprocessing_shp{outputfile[city]}.lock\"\n",
    "        # Load city boundaries\n",
    "        city_boundaries = gpd.read_file(city_boundaries_path)\n",
    "        city_postcodes = gpd.sjoin(postcode_data, city_boundaries, how='inner', op='intersects')\n",
    "\n",
    "        # Load polygons data\n",
    "        shp_path = f'urban_greenspace_classification/OSM/{city}_{year}_clipped.shp'\n",
    "        polygons_gdf = gpd.read_file(shp_path).to_crs(postcode_data.crs)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # Process in chunks\n",
    "        for start in range(0, len(city_postcodes), chunk_size):\n",
    "            chunk = city_postcodes.iloc[start:start+chunk_size]\n",
    "            # logging.info(f\"Buffering postcodes for {radius} meters, chunk {start // chunk_size}\")\n",
    "            \n",
    "            buffered_chunk = chunk.copy()\n",
    "            buffered_chunk['geometry'] = buffered_chunk['geometry'].buffer(radius)\n",
    "            buffered_chunk['total_area'] = buffered_chunk['geometry'].area\n",
    "\n",
    "            # logging.info(f\"Overlay operation for chunk {start // chunk_size}\")\n",
    "            intersected_polygons = gpd.overlay(buffered_chunk, polygons_gdf, how='intersection')\n",
    "            grouped = intersected_polygons.groupby('postcode')\n",
    "\n",
    "            for postcode, group in grouped:\n",
    "                total_area = group['total_area'].iloc[0]\n",
    "                for tag in range(5):\n",
    "                    category_area = group[group['tag'] == tag]['geometry'].area.sum()\n",
    "                    proportion = category_area / total_area if total_area else 0\n",
    "                    results.append({\n",
    "                        'postcode': postcode,\n",
    "                        'latitude': chunk.loc[chunk['postcode'] == postcode, 'latitude'].iloc[0],\n",
    "                        'longitude': chunk.loc[chunk['postcode'] == postcode, 'longitude'].iloc[0],\n",
    "                        'tag': tag,\n",
    "                        'tag_proportion': proportion,\n",
    "                        'city': city,\n",
    "                        'year': year,\n",
    "                        'buffer_radius': radius\n",
    "                    })\n",
    "\n",
    "        result_df = pd.DataFrame(results)\n",
    "\n",
    "        # Append results to the file using a lock to prevent write conflicts\n",
    "        lock = FileLock(lock_file)\n",
    "        with lock:\n",
    "            with open(output_file, 'a') as f:\n",
    "                result_df.to_csv(f, header=f.tell()==0, index=False)\n",
    "        logging.info(f\"DONE {city}, {year}, {radius}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {city}, {year}, {radius}: {e}\")\n",
    "\n",
    "def main():\n",
    "    city_file_map = {\n",
    "        'Greater_London': \"urban_greenspace_classification/Boundaries/LA_London.shp\",\n",
    "        'Greater_Manchester': \"urban_greenspace_classification/Boundaries/LA_Manchester.shp\",\n",
    "        'West_Midlands': \"urban_greenspace_classification/Boundaries/LA_Westmindlands.shp\"\n",
    "    }\n",
    "\n",
    "    tasks = [(city, year, radius) for city in city_file_map for year in range(2018, 2024) for radius in buffer_radii]\n",
    "\n",
    "\n",
    "    completed_tasks= []\n",
    "    outputfile = {\n",
    "        \"Greater_London\":\"_greater_london\",\n",
    "             \"Greater_Manchester\":\"\",\n",
    "             \"West_Midlands\":\"_westmidlands\"\n",
    "    }\n",
    "\n",
    "    for city, item in outputfile.items():   \n",
    "        output_file = f\"multiprocessing_shp{outputfile[city]}.csv\"\n",
    "        if os.path.exists(output_file):\n",
    "            csv_df = pd.read_csv(output_file, usecols=['city', 'year', 'buffer_radius'])\n",
    "            csv_df = set(csv_df[['city', 'year', 'buffer_radius']].itertuples(index=False, name=None))\n",
    "        else:\n",
    "            csv_df = set()\n",
    "        completed_tasks.extend(csv_df)  \n",
    "\n",
    "    print(completed_tasks)\n",
    "    tasks = [task for task in tasks if (task[0], task[1], task[2]) not in completed_tasks]\n",
    "    # tasks.insert(0,('Greater_Manchester', 2021, 2816))\n",
    "    max_workers = min(4, os.cpu_count())  # Adjusting max_workers further down\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for task in tasks:\n",
    "            city, year, radius = task\n",
    "            city_boundaries_path = city_file_map[city]\n",
    "            futures.append(executor.submit(process_task, city, year, radius, city_boundaries_path))\n",
    "\n",
    "        for future in futures:\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error in future: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lse",
   "language": "python",
   "name": "lse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
